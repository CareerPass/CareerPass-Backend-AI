# voice_ai.py
# ================================================================
# ìŒì„± STT ì„œë²„ (FastAPI + OpenAI Whisper)
# ================================================================

import os
import json
from io import BytesIO  # âœ… ì¶”ê°€

from dotenv import load_dotenv
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response
from pydantic import BaseModel
import openai

# -----------------------------
# 0. í™˜ê²½ ë³€ìˆ˜ / OpenAI ì„¤ì •
# -----------------------------
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

if not openai.api_key:
    raise RuntimeError("OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. (.env í™•ì¸!)")

# -----------------------------
# 1. FastAPI ì•± & CORS
# -----------------------------
app = FastAPI(title="CareerPass Voice STT")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -----------------------------
# 2. ì‘ë‹µ DTO (STT ê²°ê³¼)
# -----------------------------
class SttResult(BaseModel):
    answerText: str  # STT ê²°ê³¼ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜

# -----------------------------
# 3. í—¬ìŠ¤ì²´í¬ & íŒŒë¹„ì½˜
# -----------------------------
@app.get("/health")
async def health():
    return {"ok": True}

@app.get("/favicon.ico")
async def favicon():
    return Response(status_code=204)

# -----------------------------
# 4. í•µì‹¬ API: /analyze
# -----------------------------
@app.post("/analyze", response_model=SttResult)
async def analyze(
    meta: str = Form(...),
    file: UploadFile = File(...),
):
    """
    ğŸ§ ìŒì„± íŒŒì¼ì„ Whisperì— ë³´ë‚´ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    - meta: ì¸í„°ë·° / ì§ˆë¬¸ ì •ë³´ (ë°±ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ë„)
    - file: .m4a / .mp3 / .wav / .webm / .ogg ë“±
    """

    # 1) meta JSON íŒŒì‹±
    try:
        meta_obj = json.loads(meta)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"invalid meta json: {e}")

    interview_id = meta_obj.get("interviewId")
    question_id = meta_obj.get("questionId")
    user_id = meta_obj.get("userId")  # ì—†ì–´ë„ ë¨ (null í—ˆìš©)

    # 2) íŒŒì¼ ê¸°ë³¸ ê²€ì¦
    if not file or not file.filename:
        raise HTTPException(status_code=400, detail="file missing")

    lower_name = file.filename.lower()
    if not lower_name.endswith((".m4a", ".mp3", ".wav", ".webm", ".ogg")):
        raise HTTPException(status_code=400, detail="unsupported audio type")

    # 3) Whisper í˜¸ì¶œ (ì‹¤ì œ STT)
    try:
        # âœ… ì—…ë¡œë“œ íŒŒì¼ ë°”ì´íŠ¸ ì½ì–´ì„œ BytesIOë¡œ ê°ì‹¸ê¸°
        contents = await file.read()
        audio_bytes = BytesIO(contents)
        audio_bytes.name = file.filename  # ğŸ”¥ ì—¬ê¸°ì„œ í™•ì¥ì í¬í•¨ ì´ë¦„ì„ ë‹¬ì•„ì¤Œ

        transcription = openai.audio.transcriptions.create(
            model="gpt-4o-mini-transcribe",  # ë˜ëŠ” "whisper-1"
            file=audio_bytes,
            language="ko",
        )

        # SDK ë²„ì „ì— ë”°ë¼ text ì†ì„±ì´ ìˆê±°ë‚˜, ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ
        text = getattr(transcription, "text", None) or str(transcription)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Whisper í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    # 4) ìµœì¢… ì‘ë‹µ
    return SttResult(answerText=text)


# ë¡œì»¬ ì‹¤í–‰ìš© ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("voice_ai:app", host="0.0.0.0", port=5001, reload=True)