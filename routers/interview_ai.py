import os
import json
import logging
from typing import List, Dict, Any
from datetime import datetime

from pydantic import BaseModel, Field, ValidationError
from fastapi import FastAPI, HTTPException, APIRouter
import openai
from openai import OpenAI

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ==============================================================================
# 1. ë¼ìš°í„° ê°ì²´ ìƒì„±, í™˜ê²½ ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ==============================================================================

interview_router = APIRouter()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API Key ë° ëª¨ë¸ ID ì„¤ì •
INTERVIEW_KEY = os.environ.get("INTERVIEW_OPENAI_KEY")
CUSTOM_FINETUNED_MODEL_ID = os.environ.get("INTERVIEW_FINEDTUNED_MODEL_ID")

try:
    client = OpenAI(api_key=INTERVIEW_KEY)
    print("Interview Router OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ.")
except Exception:
    # ğŸ”¸ (ë©”ì‹œì§€ë§Œ ì‚´ì§ ë³€ê²½: ì‹¤ì œë¡œëŠ” ë” ì´ìƒ Mock ëª¨ë“œë¡œ ëŒì§€ ì•Šê¸° ë•Œë¬¸ì—)
    print("OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë©´ì ‘ ë¶„ì„ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    client = None

# ==============================================================================
# 2. ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic)
# ==============================================================================

class InterviewMeta(BaseModel):
    """AíŒ€ tb_interview Entityë¥¼ ë°˜ì˜í•œ ì„¸ì…˜ ë ˆë²¨ ë©”íƒ€ë°ì´í„°"""
    id: int
    userId: int
    jobApplied: str
    questionId: int

class AnswerDispatch(BaseModel):
    """BíŒ€ APIê°€ AíŒ€ìœ¼ë¡œë¶€í„° ë°›ì•„ì•¼ í•˜ëŠ” ì „ì²´ ì…ë ¥ ë°ì´í„° êµ¬ì¡°"""
    answerId: int
    questionText: str
    transcript: str = Field(..., description="AíŒ€ Voice AIì˜ STT ê²°ê³¼")
    resumeContent: str
    meta: InterviewMeta

class AnswerAnalysisResult(BaseModel):
    """BíŒ€ LLMì˜ ìµœì¢… ì¶œë ¥ ìŠ¤í‚¤ë§ˆ (ë©´ì ‘ í”¼ë“œë°± í•­ëª©)"""
    score: int = Field(..., ge=0, le=100)
    timeMs: int = Field(default=0)
    fluency: int = Field(..., ge=0, le=5)
    contentDepth: int = Field(..., ge=0, le=5)
    structure: int = Field(..., ge=0, le=5)
    fillerCount: int
    improvements: List[str]
    strengths: List[str]
    risks: List[str] = Field(default_factory=list)

# ==============================================================================
# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±)
# ==============================================================================

def create_fine_tuning_example(dispatch: AnswerDispatch, analysis: AnswerAnalysisResult) -> Dict[str, Any]:
    """ë‹µë³€-ë¶„ì„ ìŒì„ OpenAI JSONL í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""

    system_prompt = (
        f"ë‹¹ì‹ ì€ '{dispatch.meta.jobApplied}' ì§ë¬´ì˜ ë©´ì ‘ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ë‹µë³€, ì§€ì›ìì˜ ìê¸°ì†Œê°œì„œ ì›ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ í‰ê°€í•˜ê³ , "
        "ë°˜ë“œì‹œ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ê²°ê³¼ë¥¼ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤."
        f"JSON schema: AnswerAnalysisResult.model_json_schema()"
    )
    user_content = (
        f"--- í‰ê°€ ìš”ì²­ ---\n"
        f"ìê¸°ì†Œê°œì„œ(ì›ë¬¸): {dispatch.resumeContent}\n"
        f"ì§ˆë¬¸: {dispatch.questionText}\n"
        f"ë‹µë³€(transcript): {dispatch.transcript}\n\n"
        f"ìœ„ ë‹µë³€ì„ í‰ê°€í•˜ê³ , JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ê²°ê³¼ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”."
    )
    assistant_content = analysis.model_dump_json()

    return {
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
            {"role": "assistant", "content": assistant_content}
        ]
    }

# ==============================================================================
# 4. ë©´ì ‘ ë¶„ì„ í•µì‹¬ ë¡œì§ (LLM í˜¸ì¶œ)
# ==============================================================================

def run_analysis_with_finetuned_model(dispatch: AnswerDispatch) -> AnswerAnalysisResult:
    """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤. (ë” ì´ìƒ Mock ì‚¬ìš© X)"""

    # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ / ëª¨ë¸ ì„¤ì • ì²´í¬
    if not client:
        # í‚¤ê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´ ë°”ë¡œ 500 ì—ëŸ¬
        raise HTTPException(status_code=500, detail="OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if not CUSTOM_FINETUNED_MODEL_ID:
        # ëª¨ë¸ IDê°€ ì—†ìœ¼ë©´ ë°”ë¡œ 500 ì—ëŸ¬
        raise HTTPException(status_code=500, detail="INTERVIEW_FINEDTUNED_MODEL_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # 2. ë©”ì‹œì§€ êµ¬ì„± (í”„ë¡¬í”„íŠ¸ êµ¬ì„±)
    messages = create_fine_tuning_example(
        dispatch,
        analysis=AnswerAnalysisResult.model_construct()
    )['messages']

    # 3. LLM í˜¸ì¶œ ì‹œë„ (í•„ìˆ˜, ì‹¤íŒ¨í•˜ë©´ ë°”ë¡œ 500 ì—ëŸ¬)
    try:
        print(f"LLM í˜¸ì¶œ: {CUSTOM_FINETUNED_MODEL_ID} (Session ID: {dispatch.meta.id})")
        response = client.chat.completions.create(
            model=CUSTOM_FINETUNED_MODEL_ID,
            response_format={"type": "json_object"},
            messages=messages,
            temperature=0.0
        )
        raw_llm_output = response.choices[0].message.content
        logger.info(f"LLM ì‘ë‹µ ì›ë¬¸: {raw_llm_output[:50]}...")
        #print(f"LLM ì‘ë‹µ ì›ë¬¸: {raw_llm_output}")
    except Exception as e:
        logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {type(e).__name__} - {e}", exc_info=True)
        #print(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        # ğŸ”¸ ì—¬ê¸°ì„œ ë” ì´ìƒ Mockìœ¼ë¡œ ëŒ€ì²´í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ 500 ì—ëŸ¬
        raise HTTPException(status_code=500, detail=f"ë©´ì ‘ LLM í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ë‚´ë¶€ ë¡œê·¸ í™•ì¸ í•„ìš”: {type(e).__name__})")

    # 4. JSON ìœ íš¨ì„± ê²€ì¦
    try:
        logger.info(f"DEBUG: LLM ì›ë³¸ ì¶œë ¥ (JSON):\n{raw_llm_output}")
        analysis_result = AnswerAnalysisResult.model_validate_json(raw_llm_output)
        return analysis_result
    except ValidationError as e:
        logger.error(f"LLM ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ ì˜¤ë¥˜ ë°œìƒ. Pydantic ì˜¤ë¥˜ ìƒì„¸:", exc_info=True)
        logger.error(f"DEBUG: ë¬¸ì œì˜ ì›ë³¸ JSON: {raw_llm_output}")
        raise HTTPException(status_code=500, detail=f"LLMì´ ìœ íš¨í•˜ì§€ ì•Šì€ JSONì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. (Pydantic ì˜¤ë¥˜: {str(e)[:50]}...)")


# ==============================================================================
# 5. FastAPI ì—”ë“œí¬ì¸íŠ¸ ì •ì˜ (AíŒ€ì´ í˜¸ì¶œí•  API)
# ==============================================================================

@interview_router.post("/analysis/interview/run", response_model=AnswerAnalysisResult)
async def analyze_interview_answer(dispatch_data: AnswerDispatch):
    """
    HTTP POST ìš”ì²­ì„ ë°›ì•„ ë©´ì ‘ ë‹µë³€ ë¶„ì„ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
    """
    print(f"[{datetime.now()}] ë¶„ì„ ìš”ì²­ ìˆ˜ì‹ : Answer ID {dispatch_data.answerId} (Session ID: {dispatch_data.meta.id})")

    analysis_result = run_analysis_with_finetuned_model(dispatch_data)

    return analysis_result