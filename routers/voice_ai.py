# voice_ai.py
# ================================================================
# ìŒì„± STT ì„œë²„ (FastAPI + OpenAI Whisper)
# ================================================================

import os
import json
import logging
from io import BytesIO  # âœ… íŒŒì¼ ë°ì´í„°ë¥¼ ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©

from fastapi import UploadFile, File, Form, HTTPException, APIRouter
from fastapi.responses import Response
from pydantic import BaseModel
from openai import OpenAI
from openai import OpenAIError # ğŸ’¡ OpenAI API ê´€ë ¨ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# -----------------------------
# 0. í™˜ê²½ ë³€ìˆ˜ / OpenAI ì„¤ì •
# -----------------------------

voice_router = APIRouter()

# ğŸš¨ ì£¼ì˜: ì „ì—­ ì´ˆê¸°í™” ì½”ë“œ (VOICE_KEY, client ì •ì˜ ë¸”ë¡)ëŠ” 
# íƒ€ì´ë° ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.


# -----------------------------
# 2. ì‘ë‹µ DTO (STT ê²°ê³¼)
# -----------------------------
class SttResult(BaseModel):
    answerText: str  # STT ê²°ê³¼ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜

# -----------------------------
# 3. í—¬ìŠ¤ì²´í¬ & íŒŒë¹„ì½˜
# -----------------------------
@voice_router.get("/health")
async def health():
    return {"ok": True}

@voice_router.get("/favicon.ico")
async def favicon():
    return Response(status_code=204)

# -----------------------------
# 4. í•µì‹¬ API: /analyze
# -----------------------------
@voice_router.post("/analyze", response_model=SttResult)
async def analyze(
    meta: str = Form(...),
    file: UploadFile = File(...),
):
    """
    ğŸ§ ìŒì„± íŒŒì¼ì„ Whisperì— ë³´ë‚´ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    - meta: ì¸í„°ë·° / ì§ˆë¬¸ ì •ë³´ (ë°±ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ë„)
    - file: .m4a / .mp3 / .wav / .webm / .ogg ë“±
    """

    # 1) meta JSON íŒŒì‹±
    try:
        meta_obj = json.loads(meta)
        logger.info(f"STT ìš”ì²­ ìˆ˜ì‹ : Interview ID={meta_obj.get('interviewId')}, íŒŒì¼ëª…={file.filename}")
    except Exception as e:
        logger.error(f"ë©”íƒ€ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        # âš ï¸ (ì¶”ê°€) ìš”ì²­ì„ ë³´ë‚´ëŠ” í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ ìœ íš¨í•œ JSON ë¬¸ìì—´("{"interviewId": 0}")ì„ ë³´ë‚´ì•¼ í•©ë‹ˆë‹¤.
        raise HTTPException(status_code=400, detail=f"invalid meta json: {e}")

    interview_id = meta_obj.get("interviewId")
    question_id = meta_obj.get("questionId")
    user_id = meta_obj.get("userId")  # ì—†ì–´ë„ ë¨ (null í—ˆìš©)

    # 2) íŒŒì¼ ê¸°ë³¸ ê²€ì¦
    if not file or not file.filename:
        logger.error("íŒŒì¼ ëˆ„ë½ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=400, detail="file missing")

    lower_name = file.filename.lower()
    if not lower_name.endswith((".m4a", ".mp3", ".wav", ".webm", ".ogg")):
        logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ íƒ€ì…: {file.filename}")
        raise HTTPException(status_code=400, detail="unsupported audio type")

    # 3) Whisper í˜¸ì¶œ (ì‹¤ì œ STT)
    try:
        # ğŸ’¡ [í•µì‹¬ í•´ê²°] ì§€ì—° ì´ˆê¸°í™”: í•¨ìˆ˜ í˜¸ì¶œ ì‹œì ì— í‚¤ë¥¼ ì½ì–´ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        local_voice_key = os.environ.get("QUESTION_VOICE_OPENAI_KEY")
        if not local_voice_key:
            logger.error("QUESTION_VOICE_OPENAI_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            raise HTTPException(status_code=500, detail="Whisper í˜¸ì¶œ ì‹¤íŒ¨: OpenAI API Key ì„¤ì • ëˆ„ë½")
        
        # ğŸ”‘ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (OpenAI API Key ëˆ„ë½ ì˜¤ë¥˜ í•´ê²°)
        client = OpenAI(api_key=local_voice_key) 
        
        # âœ… ì—…ë¡œë“œ íŒŒì¼ ë°”ì´íŠ¸ ì½ì–´ì„œ BytesIOë¡œ ê°ì‹¸ê¸°
        contents = await file.read()
        audio_bytes = BytesIO(contents)
        audio_bytes.name = file.filename  # í™•ì¥ì í¬í•¨ ì´ë¦„ì„ ë‹¬ì•„ì¤Œ

        logger.info(f"Whisper API í˜¸ì¶œ ì‹œë„: ëª¨ë¸=whisper-1, íŒŒì¼ í¬ê¸°={len(contents)} bytes") 

        transcription = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_bytes,
            language="ko",
        )

        text = getattr(transcription, "text", None) or str(transcription)

        logger.info(f"Whisper í˜¸ì¶œ ì„±ê³µ: í…ìŠ¤íŠ¸ ê¸¸ì´={len(text)}")

    except OpenAIError as e:
        # OpenAI API í˜¸ì¶œ ìì²´ì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ ì²˜ë¦¬ (ì˜ˆ: ì˜ëª»ëœ í‚¤, ëª¨ë¸)
        logger.error(f"Whisper API ì˜¤ë¥˜: {e.status_code} - {e.response.text}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Whisper API ì˜¤ë¥˜: {e}")
    except Exception as e:
        logger.error(f"Whisper í˜¸ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Whisper í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    # 4) ìµœì¢… ì‘ë‹µ
    return SttResult(answerText=text)